{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952c5a77",
   "metadata": {},
   "source": [
    "# **Multi-Index DataFrame**\n",
    "\n",
    "Create a multi-index DataFrame using the following data and \n",
    "perform indexing to select sales of 'Product B' in '2023-Q2'\n",
    "| Year | Quarter | Product | Sales | \n",
    "   |------|---------|---------|-------| \n",
    "   | 2023 | Q1      | A       | 200   | \n",
    "   | 2023 | Q2      | B       | 350   | \n",
    "   | 2023 | Q3      | C       | 400   | \n",
    "   | 2023 | Q2      | A       | 300   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72363de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Index DataFrame:\n",
      "                      Sales\n",
      "Year Quarter Product       \n",
      "2023 Q1      A          200\n",
      "     Q2      B          350\n",
      "     Q3      C          400\n",
      "     Q2      A          300\n",
      "\n",
      "\n",
      "Sales for Product B in Q2 2023: 350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#create a multi-index DataFrame\n",
    "data = {\n",
    "    'Year': [2023, 2023, 2023, 2023],\n",
    "    'Quarter': ['Q1', 'Q2', 'Q3', 'Q2'],\n",
    "    'Product': ['A', 'B', 'C', 'A'],\n",
    "    'Sales': [200, 350, 400, 300]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(['Year', 'Quarter', 'Product'], inplace=True)\n",
    "print(\"Multi-Index DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "B_sales = df.loc[(2023, \"Q2\", \"B\"), \"Sales\"]\n",
    "print(f\"Sales for Product B in Q2 2023: {B_sales}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e4db2",
   "metadata": {},
   "source": [
    "# **Datetime Operations**\n",
    "\n",
    " Read a CSV file `transactions.csv` with columns \n",
    "`TransactionID`, `Date`, `Amount`. Convert `Date` to datetime, \n",
    "extract `month` and `day`, and filter transactions from January \n",
    "2025. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752021d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions from January 2025:\n",
      "   TransactionID       Date  Amount  Month  Day\n",
      "0              1 2025-01-05     250      1    5\n",
      "1              2 2025-01-15     400      1   15\n",
      "4              5 2025-01-20     300      1   20\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:/pythonML-class/transactions.csv')\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extracting month and day\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "# Filtering the transactions from January 2025\n",
    "jan = df[df['Date'].dt.month == 1]\n",
    "print(\"Transactions from January 2025:\")\n",
    "print(jan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd57c54",
   "metadata": {},
   "source": [
    "# **Handling Missing Data**\n",
    "\n",
    "Given a DataFrame with missing values in `Age` and `Salary`, \n",
    "perform the following: \n",
    "   - Fill missing `Age` with median age. \n",
    "   - Fill missing `Salary` with forward fill method. \n",
    "   - Drop rows where all values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7514380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with Missing Values:\n",
      "      Name   Age   Salary\n",
      "0    Alice  25.0  50000.0\n",
      "1      Bob   NaN  60000.0\n",
      "2  Charlie  30.0      NaN\n",
      "3    David   NaN      NaN\n",
      "4      Eva  22.0  52000.0\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [25, None, 30, None, 22],\n",
    "    'Salary': [50000, 60000, None, None, 52000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame with Missing Values:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11416\\288714547.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(median_age, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11416\\288714547.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Salary'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11416\\288714547.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Salary'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Filling missing Age with median age\n",
    "median_age = df['Age'].median()\n",
    "df['Age'].fillna(median_age, inplace=True)\n",
    "# Filling missing Salary with forward fill method\n",
    "df['Salary'].fillna(method='ffill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after Handling Missing Data:\n",
      "      Name   Age   Salary\n",
      "0    Alice  25.0  50000.0\n",
      "1      Bob  25.0  60000.0\n",
      "2  Charlie  30.0  60000.0\n",
      "3    David  25.0  60000.0\n",
      "4      Eva  22.0  52000.0\n"
     ]
    }
   ],
   "source": [
    "df.dropna(how='all', inplace=True)\n",
    "print(\"DataFrame after handling the missing data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b413a1f",
   "metadata": {},
   "source": [
    "# **Pivot Table** \n",
    "   Using the following dataset, create a pivot table showing\n",
    "   average salary for each Department per Gender. \n",
    " \n",
    "   | Name  | Department | Gender | Salary | \n",
    "   |-------|------------|--------|--------| \n",
    "   | John  | IT         | M      | 75000  | \n",
    "   | Alice | IT         | F      | 62000  | \n",
    "   | Bob   | HR         | M      | 50000  | \n",
    "   | Clara | HR         | F      | 52000  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc35586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender            F        M\n",
      "Department                  \n",
      "HR          52000.0  50000.0\n",
      "IT          62000.0  75000.0\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Clara'],\n",
    "    'Department': ['IT', 'IT', 'HR', 'HR'],\n",
    "    'Gender': ['M', 'F', 'M', 'F'],\n",
    "    'Salary': [75000, 62000, 50000, 52000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pivot_table = pd.pivot_table(df, values='Salary', index='Department',columns=\"Gender\", aggfunc=\"mean\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c9b841",
   "metadata": {},
   "source": [
    "# **Apply & Lambda**\n",
    "   Create a column Tax where: \n",
    "   - If Salary > 60000, tax is 10% \n",
    "   - Else tax is 5% \n",
    "   Use apply() with a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80326472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Tax column:\n",
      "    Name Department Gender  Salary     Tax\n",
      "0   John         IT      M   75000  7500.0\n",
      "1  Alice         IT      F   62000  6200.0\n",
      "2    Bob         HR      M   50000  2500.0\n",
      "3  Clara         HR      F   52000  2600.0\n"
     ]
    }
   ],
   "source": [
    "df['Tax'] = df['Salary'].apply(lambda x: x * 0.10 if x > 60000 else x * 0.05)\n",
    "print(\"DataFrame with Tax column:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594c3eb",
   "metadata": {},
   "source": [
    "# **Merging DataFrames**\n",
    "   Merge the following two DataFrames on EmployeeID and \n",
    "display only employees present in both: \n",
    " \n",
    "   df1: \n",
    "   | EmployeeID | Name  | Department | \n",
    "   |------------|-------|------------| \n",
    "   | 101        | John  | IT         | \n",
    "   | 102        | Alice | HR         | \n",
    " \n",
    "   df2: \n",
    "   | EmployeeID | Salary | \n",
    "   |------------|--------|\n",
    "   | 101        | 75000  | \n",
    "   | 103        | 62000  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebbb0645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID  Name Department  Salary\n",
      "0         101  John         IT   75000\n"
     ]
    }
   ],
   "source": [
    "data1 = {\n",
    "    'EmployeeID': [101, 102],\n",
    "    'Name': ['John', 'Alice'],\n",
    "    'Department': ['IT', 'HR']\n",
    "}\n",
    "data2 = {\n",
    "    'EmployeeID': [101, 103],\n",
    "    'Salary': [75000, 62000]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "merged_df = pd.merge(df1, df2, on='EmployeeID', how='inner')\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4625699",
   "metadata": {},
   "source": [
    "# **String Operations**\n",
    "   From a column Email, extract username (before @) and \n",
    "domain (after @) into separate columns using vectorized \n",
    "string methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dbaa649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Email        Username      Domain\n",
      "0  dipeshresthaaa@gmail.com  dipeshresthaaa   gmail.com\n",
      "1        rahul123@yahoo.com        rahul123   yahoo.com\n",
      "2       susanytx@nlk.org.np        susanytx  nlk.org.np\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Email': ['dipeshresthaaa@gmail.com', 'rahul123@yahoo.com', 'susanytx@nlk.org.np']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['Username'] = df['Email'].str.split('@').str[0]\n",
    "df['Domain'] = df['Email'].str.split('@').str[1]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66958012",
   "metadata": {},
   "source": [
    "# **GroupBy with Multiple Aggregations**\n",
    "   Group a sales dataset by Region and Product and calculate: \n",
    "   - Total Sales \n",
    "   - Average Sales \n",
    "   - Count of Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f144a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region Product  Total_Sales  Average_Sales  Transaction_Count\n",
      "0   East       A          500          250.0                  2\n",
      "1  North       A          400          400.0                  1\n",
      "2  South       B          350          350.0                  1\n",
      "3   West       B          450          450.0                  1\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Region': ['East', 'South', 'North', 'East', 'West'],\n",
    "    'Product': ['A', 'B', 'A', 'A', 'B'],\n",
    "    'Sales': [200, 350, 400, 300, 450]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "grouped = df.groupby(['Region', 'Product']).agg(\n",
    "    Total_Sales=('Sales', 'sum'),\n",
    "    Average_Sales=('Sales', 'mean'),\n",
    "    Transaction_Count=('Sales', 'count')\n",
    ").reset_index()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a650f341",
   "metadata": {},
   "source": [
    "# **Reshaping Data**\n",
    "   Convert a wide-format DataFrame into a long-format using \n",
    "melt() and then pivot it back to original wide format using \n",
    "pivot_table()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44111058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year   Quarter  Sales\n",
      "0  2025  Q1_Sales    200\n",
      "1  2024  Q1_Sales    150\n",
      "2  2023  Q1_Sales    300\n",
      "3  2023  Q1_Sales    250\n",
      "4  2025  Q2_Sales    220\n",
      "5  2024  Q2_Sales    180\n",
      "6  2023  Q2_Sales    320\n",
      "7  2023  Q2_Sales    270\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Year': [2025, 2024, 2023, 2023],\n",
    "    'Q1_Sales': [200, 150, 300, 250],\n",
    "    'Q2_Sales': [220, 180, 320, 270]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "melt_df = pd.melt(df, id_vars=['Year'], value_vars=['Q1_Sales', 'Q2_Sales'], var_name='Quarter', value_name='Sales')\n",
    "print(melt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af297731",
   "metadata": {},
   "source": [
    "# **Advanced Filtering**\n",
    "    Using a DataFrame with columns Name, Age, Department, \n",
    "Salary, apply multiple conditions to filter: \n",
    "    - Employees in IT department with Age > 30 \n",
    "    - Salary between 50000 and 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c4faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame:\n",
      "   Name  Age Department  Salary\n",
      "4  Hari   32         IT   68000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    'Name': ['Ram', 'Maya', 'Chitra', 'Shyamm', 'Hari'],\n",
    "    'Age': [23, 34, 29, 40, 32],\n",
    "    'Department': ['IT', 'HR', 'IT', 'CS', 'IT'],\n",
    "    'Salary': [62000, 75000, 55000, 45000, 68000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "filtered_df = df[(df['Department'] == 'IT') & (df['Age'] > 30) & (df['Salary'].between(50000, 70000))]\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(filtered_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
